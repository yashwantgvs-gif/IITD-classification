import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Function to implement Naive Bayes algorithm
def naive_bayes(x_train, y_train):
    # Calculate class probabilities
    classes = np.unique(y_train)
    class_probs = {}
    for class_label in classes:
        class_probs[class_label] = np.sum(y_train == class_label) / len(y_train)

    # Calculate feature probabilities for each class
    feature_probs = {}
    for feature in x_train.columns:
        feature_probs[feature] = {}
        for class_label in classes:
            class_data = x_train[y_train == class_label][feature]
            feature_probs[feature][class_label] = class_data.value_counts() / len(class_data)

    # Make predictions
    predicted_labels = []
    for _, sample in x_train.iterrows():
        class_scores = {}
        for class_label in classes:
            score = class_probs[class_label]
            for feature in x_train.columns:
                feature_value = sample[feature]
                if feature_value in feature_probs[feature][class_label]:
                    score *= feature_probs[feature][class_label][feature_value]
                else:
                    score *= 1e-10  # Smoothing for unseen feature values
            class_scores[class_label] = score
        predicted_labels.append(max(class_scores, key=class_scores.get))

    # Return the predicted labels
    return predicted_labels

# Function to implement K-Nearest Neighbors algorithm
def k_nearest_neighbors(x_train, y_train, k):
    # Function to calculate Euclidean distance between two samples
    def euclidean_distance(sample1, sample2):
        return np.sqrt(np.sum((sample1 - sample2) ** 2))

    # Make predictions
    predicted_labels = []
    for _, sample in x_train.iterrows():
        distances = []
        for _, train_sample in x_train.iterrows():
            distance = euclidean_distance(sample, train_sample)
            distances.append(distance)
        nearest_indices = np.argsort(distances)[:k]
        nearest_labels = y_train.iloc[nearest_indices]
        predicted_label = nearest_labels.value_counts().idxmax()
        predicted_labels.append(predicted_label)

    # Return the predicted labels
    return predicted_labels

# Load the data from Excel files
train_data = pd.read_csv(r"C:\Users\ASUS\Downloads\train.csv")
test_data = pd.read_csv(r"C:\Users\ASUS\Downloads\test.csv")
submission_data = pd.read_csv(r"C:\Users\ASUS\Downloads\gender_submission.csv")

# Preprocessing steps
# Combine train_data and test_data for preprocessing
combined_data = pd.concat([train_data, test_data], axis=0)

# Handle missing values (if any)
combined_data.fillna(0, inplace=True)

# Perform one-hot encoding for categorical variables
combined_data = pd.get_dummies(combined_data)

# Separate the preprocessed data back into train_data and test_data
train_data = combined_data[:len(train_data)]
test_data = combined_data[len(train_data):]

# Extract features and target variable from the train_data
x_train = train_data.drop("Survived", axis=1)
y_train = train_data["Survived"]

# Perform Naive Bayes classification
naive_bayes_predictions = naive_bayes(x_train, y_train)

# Perform K-Nearest Neighbors classification
k = 5  # Set the value of k for K-Nearest Neighbors
knn_predictions = k_nearest_neighbors(x_train, y_train, k)

# Calculate accuracy of Naive Bayes predictions
naive_bayes_accuracy = accuracy_score(true_labels, naive_bayes_predictions)
print("Naive Bayes Accuracy:", naive_bayes_accuracy)

# Calculate accuracy of K-Nearest Neighbors predictions
knn_accuracy = accuracy_score(true_labels, knn_predictions)
print("K-Nearest Neighbors Accuracy:", knn_accuracy)

# Generate confusion matrix for Naive Bayes predictions
naive_bayes_cm = confusion_matrix(true_labels, naive_bayes_predictions)
print("Naive Bayes Confusion Matrix:")
print(naive_bayes_cm)

# Generate confusion matrix for K-Nearest Neighbors predictions
knn_cm = confusion_matrix(true_labels, knn_predictions)
print("K-Nearest Neighbors Confusion Matrix:")
print(knn_cm)

# Generate classification report for Naive Bayes predictions
naive_bayes_report = classification_report(true_labels, naive_bayes_predictions)
print("Naive Bayes Classification Report:")
print(naive_bayes_report)

# Generate classification report for K-Nearest Neighbors predictions
knn_report = classification_report(true_labels, knn_predictions)
print("K-Nearest Neighbors Classification Report:")
print(knn_report)

# Visualization using Pandas, NumPy, and Matplotlib
# Define the class labels
class_labels = ['Not Survived', 'Survived']

# Calculate the number of predictions for each class
naive_bayes_counts = np.bincount(naive_bayes_predictions)
knn_counts = np.bincount(knn_predictions)

# Create a bar plot to visualize the prediction counts for Naive Bayes
plt.figure(figsize=(8, 6))
plt.bar(class_labels, naive_bayes_counts, color='blue')
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Prediction Counts for Naive Bayes')
plt.show()

# Create a bar plot to visualize the prediction counts for K-Nearest Neighbors
plt.figure(figsize=(8, 6))
plt.bar(class_labels, knn_counts, color='green')
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Prediction Counts for K-Nearest Neighbors')
plt.show()
